{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8becb0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 10215/16649 [06:06<03:50, 27.86it/s] \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import xarray as xr\n",
    "import utils.utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from urllib.error import HTTPError\n",
    "from scipy import interpolate\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "file_num = 0\n",
    "\n",
    "T_RH_PATH = 'D:/ERA5_t_rh_aggregated_3h'\n",
    "TCW_PATH = 'D:/ERA5_tcw_aggregated_3h'\n",
    "sample_mswep = xr.open_dataset('D:/sample_mswep.nc').isel(time=0)\n",
    "box_radius = utils.utils.convert_box_radius(500, res=0.1)\n",
    "\n",
    "# only do a fraction of the df per notebook, as I run 15 notebooks in parallel to accelerate the process\n",
    "df = pd.read_csv('data/IBTrACS/ibtracs.above_34.csv')\n",
    "step = int(np.floor(len(df) / 15)) # 15 is the number of notebooks in parellel I run\n",
    "start = step * file_num \n",
    "end = step * (file_num + 1)\n",
    "df = df[start:end]\n",
    "\n",
    "\n",
    "new_df_as_list = []\n",
    "done = 0\n",
    "nans_found = 0\n",
    "timesteps_not_found = 0 # num of files not found because the timestep was not a multiple of 3h\n",
    "had_inf_bias = 0 # num of files that had infinite bias between ERA5 and MSWEP, likely because the TC was misplaced/absent in ERA5\n",
    "wrong_shapes = 0 # num of files that had the wrong shape, likely because they were too close to lon=180\n",
    "was_empty_era5 = 0 # num of files that had no rainfall\n",
    "was_empty_mswep = 0 # num of files that had no rainfall\n",
    "for idx, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    TC_lat = row.LAT\n",
    "    TC_lon = row.LON\n",
    "    if TC_lon > 179.9:\n",
    "        TC_lon -= 360\n",
    "    TC_wind = row.WMO_WIND\n",
    "    idx = row.IDX_ORIG\n",
    "    iso_time = utils.utils.add_to_iso_time(row.ISO_TIME, hours_delta=1, minutes_delta=30)\n",
    "    year, month, day, hour = utils.utils.convert_iso_time_3h(iso_time)\n",
    "    \n",
    "    with xr.open_dataset(f'{ERA5_PATH}/ERA5_tp_{year}_{month}.nc') as era5_ds:\n",
    "        # select current timestep in ERA5\n",
    "        try:\n",
    "            timestep_slice = utils.utils.slice_ds_timestep(era5_ds, iso_time, 'ERA5')\n",
    "        except IndexError:\n",
    "            timesteps_not_found += 1\n",
    "            continue\n",
    "        era5_interp_mswep = utils.utils.interp_era5_to_mswep(timestep_slice, sample_mswep)\n",
    "        # get domain lats and lons (used to crop data around TC centre)\n",
    "        domain_lats = era5_interp_mswep['latitude'].values\n",
    "        domain_lons = era5_interp_mswep['longitude'].values\n",
    "        # find the id inside of domain_lats/domain_lons that corresponds to the TC centre\n",
    "        TC_lat_id = utils.utils.find_id(TC_lat, domain_lats)\n",
    "        TC_lon_id = utils.utils.find_id(TC_lon, domain_lons)\n",
    "        # box ERA5 around IBTrACS TC centre\n",
    "        boxed_era5 = utils.utils.box_var(era5_interp_mswep, TC_lat_id, TC_lon_id, box_radius, domain_lats, domain_lons, idx)\n",
    "        if np.isnan(boxed_era5).any():\n",
    "            boxed_era5 = boxed_era5.fillna(0)\n",
    "        tp_tot_era5 = np.sum(boxed_era5)*1000\n",
    "    if tp_tot_era5 < 10:\n",
    "        was_empty_era5 += 1\n",
    "        continue\n",
    "    \n",
    "    with xr.open_dataset(f'{MSWEP_PATH}/MSWEP_tp_{year}_{month}.nc') as mswep_ds:\n",
    "        # select current timestep in MSWEP\n",
    "        try:\n",
    "            timestep_slice = utils.utils.slice_ds_timestep(mswep_ds, iso_time, 'MSWEP')\n",
    "        except IndexError:\n",
    "            timesteps_not_found += 1\n",
    "            continue\n",
    "        # get domain lats and lons (used to crop data around TC centre)\n",
    "        domain_lats = timestep_slice['lat'].values\n",
    "        domain_lons = timestep_slice['lon'].values\n",
    "        # find the id inside of domain_lats/lons that corresponds to the TC centre\n",
    "        TC_lat_id = utils.utils.find_id(TC_lat, domain_lats)\n",
    "        TC_lon_id = utils.utils.find_id(TC_lon, domain_lons)\n",
    "        # box ERA5 around IBTrACS TC centre\n",
    "        boxed_mswep = utils.utils.box_var(timestep_slice, TC_lat_id, TC_lon_id, box_radius, domain_lats, domain_lons, idx)\n",
    "        tp_tot_mswep = np.sum(boxed_mswep)\n",
    "    if tp_tot_mswep < 10:\n",
    "        was_empty_mswep += 1\n",
    "        continue\n",
    "    \n",
    "    # check that the bias (%) between ERA5 and MSWEP is not infinite (it would indicate that\n",
    "    # the TC in ERA5 was misplaced/missed)\n",
    "    bias = tp_tot_era5 - tp_tot_mswep\n",
    "    bias_pc = bias * 100/tp_tot_era5\n",
    "    bias_is_inf = np.isinf(bias_pc)\n",
    "    # check that there are no nans in either snapshot\n",
    "    nans_present = np.isnan(boxed_era5).any() or np.isnan(boxed_mswep).any()\n",
    "    # check that the shape is correct\n",
    "    wrong_shape = not(boxed_era5.shape == boxed_mswep.shape == (91, 91))\n",
    "    if nans_present or bias_is_inf or wrong_shape:\n",
    "        if wrong_shape:\n",
    "            wrong_shapes += 1\n",
    "        elif nans_present:\n",
    "            nans_found += 1\n",
    "        elif bias_is_inf:\n",
    "            had_inf_bias +=1\n",
    "        continue\n",
    "    new_df_as_list.append(row)\n",
    "    # save ERA5 and MSWEP snapshots\n",
    "    boxed_era5.to_netcdf(f'data/train_large/ERA5_tp/ERA5_tp_cropped_{idx}.nc')\n",
    "    boxed_mswep.to_netcdf(f'data/train_large/MSWEP_tp/MSWEP_tp_cropped_{idx}.nc')\n",
    "    # update count of saved files\n",
    "    done +=1\n",
    "    \n",
    "new_df = pd.DataFrame(new_df_as_list, columns = df.columns.to_list())\n",
    "new_df.to_csv(f'data/IBTrACS/ibtracs.1980-2020.{start}-{end}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "242e1c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped because close to 180 lon: 0\n",
      "Skipped because bias infinite: 0\n",
      "Skipped because had nans: 0\n",
      "Skipped because era5 was empty: 0\n",
      "Skipped because mswep was empty: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'Skipped because close to 180 lon: {wrong_shapes}')\n",
    "print(f'Skipped because bias infinite: {had_inf_bias}')\n",
    "print(f'Skipped because had nans: {nans_found}')\n",
    "print(f'Skipped because era5 was empty: {was_empty_era5}')\n",
    "print(f'Skipped because mswep was empty: {was_empty_mswep}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60db8a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
